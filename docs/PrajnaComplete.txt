Full Diagnostic of TORI System: Extraction, Prajna Memory, Dashboard, and APIs

Technical Review of TORI System Integration
1. PDF Concept Extraction Quality
Current Implementation: The PDF parsing in TORI relies on the AdvancedPDFProcessor (from advanced_pdf_processor.py) which reads PDF text (using PyMuPDF or PyPDF2) and then performs very simplistic keyword extraction. The _extract_key_concepts function simply splits text into words, filters out short/common words, and counts frequencies, returning the top 20 most frequent words. In practice, this rudimentary approach often yields only a few “concepts” – typically generic terms or repeats – even for rich technical PDFs. For example, if a PDF contains many unique technical terms each mentioned once or twice, the current logic might only surface a couple of frequently occurring words (sometimes as few as 3), missing most key concepts. Root Cause: The extraction logic is too shallow. It does not recognize multi-word terms, scientific entities, or context; it purely counts single-word frequencies. It also uses a limited stop-word list and a length filter (>5 chars), which can inadvertently exclude important shorter terms or phrases. As a result, the “concepts” field for each PDF is extremely sparse (e.g. a test PDF yielded only 3 generic concepts). Recommendations for Improvement:
Use NLP for Keyphrase Extraction: Integrate an NLP library (spaCy, NLTK, or Gensim) or algorithms like RAKE or TextRank to extract meaningful key phrases (not just single words). These can identify multi-word terms and domain-specific entities that the frequency approach misses.
Leverage PDF Structure: The code already attempts to capture sections (abstract, conclusion, etc.), but concept extraction could be improved by focusing on titles, headings, and bold terms in the PDF (often indicative of key concepts). Using the PDF structure (e.g., font size or section titles) can guide concept identification.
Expand Stop-word/Filtering: Use a comprehensive stop-word list and possibly a domain-specific glossary. Ensure that the filter doesn’t drop shorter but significant terms (e.g. “AI” or “CPU” are under 5 characters but are key concepts in some documents).
Semantic Analysis: Consider embedding-based approaches – for example, use a transformer model to identify important concepts or summarize the document, then extract nouns/noun phrases from the summary as concepts. This would yield more semantic concepts rather than just frequent words.
Pagination Limit: Note that the current code only reads up to 100 pages of a PDF. This is fine for most papers, but if processing books or very large docs, ensure this limit is documented or made configurable.
By adopting these improvements, concept extraction will be deeper and broader – capturing dozens of meaningful concepts instead of a handful. This richer concept set will form a better knowledge base for Prajna.
2. Prajna Integration of Extracted Concepts
Data Routing to Prajna: Originally, there was a disconnect between PDF extraction and Prajna’s memory. In the previous implementation (AdvancedDataProcessor in advanced_prajna_processor.py), the _process_pdf method didn’t actually incorporate any extracted content – it returned a placeholder knowledge entry with hard-coded concepts ['document','pdf','text_content']
file-71z6jnjcbte3moymjnxfiq
 instead of using real PDF-derived concepts. This means earlier the PDF’s key concepts weren’t reaching Prajna’s concept mesh at all. Current Integration (After Phases): The integration work aimed to bridge this gap. Now, when a PDF is uploaded and extracted with target “prajna”, the system should:
Extraction: Use the advanced PDF processor to generate a knowledge entry (including key_concepts, summary, metadata, etc.). This was implemented in the extract API endpoint (newly added – see Section 4) which likely calls the PDF processor and obtains the analysis dict (with key_concepts, citations_count, academic_sections, etc.).
Injection into Concept Mesh: After extraction, the code should take the resulting concepts and insert them into Prajna’s memory structures. In Prajna, the ConceptMesh/memory API (e.g. via prajna.memory.context_builder or concept_mesh_api) provides methods to add new concepts/nodes. The integration should call these, creating new concept nodes for each extracted key concept, and linking them appropriately (possibly tagging them with the source document or context).
Verification: Ensure that when extraction is done with target “prajna”, those concepts appear in Prajna’s live knowledge base. Practically, this means after running extraction, one should be able to go to the dashboard’s Concept Mesh/Graph view and find the newly added concept nodes (and possibly see connections if the system links them to existing concepts). Also, Prajna’s reasoning (the Q&A voice or chat system) should now incorporate that knowledge. For example, if a concept “Hyperdimensional Computing” was in the PDF, after ingestion, asking Prajna about it should yield an informed answer, indicating the data made it into Prajna’s cortex. Findings: As of the latest code, the concept routing is partially in place but needs confirmation: The extraction pipeline prepares the data, but we must confirm that the call to actually add to Prajna’s memory occurs. Look at functions in prajna/memory/soliton_interface.py or context_builder.py – likely there’s a function like add_concept or ingest_concept. If those aren’t invoked in the extraction flow, that’s a missing link. The code should be updated so that after obtaining key_concepts list, it iterates through them (or the whole knowledge entry) and uses Prajna’s memory API to insert each concept (with relationships if any). Prajna’s Voice Utilization: Prajna’s reasoning engine (prajna.core.prajna_mouth and related modules) should automatically use the updated concept mesh, as long as the data is in the memory graph. We should verify that Prajna’s concept mesh is updated in memory (not just written to a JSON file). The advanced PDF processor currently saves a JSON (prajna_pdf_knowledge.json), which is good for persistence, but for immediate use in Prajna’s live session, the data should also be loaded into memory. If not already happening, a fix is to have the extraction endpoint call a Prajna API (perhaps via prajna.api.prajna_api.add_knowledge(knowledge_entry)) to inject it. In summary, after the integration, extracted concepts should be flowing into Prajna’s concept mesh, enabling the AI to reason over them in real-time.
3. Dashboard Upload & UI Flow Issues
PDF Upload Experience: The dashboard provides an interface to upload PDFs, which presumably triggers the backend /api/upload route (see next section). The intended flow is: user clicks an “Upload” button or drags a file, the file picker opens, user selects a PDF, and it uploads in the background. We need to address two observed issues:
Double-Click Reopens File Selector: Users reported that after selecting a file, a second file dialog opens or the same dialog reappears on a double-click. This suggests that the UI may be opening the file chooser on a click event that isn’t properly debounced or perhaps the onChange handler triggers it again. Another possibility is that the <input type="file"> is not hidden properly behind a custom button, causing a double event. Solution: Ensure the file input is triggered only once per user action. If using a custom button that calls input.click(), make sure it’s not also submitting the form or causing a full page reload. Also, disable the upload button or file input after one selection until the upload is done, to prevent rapid double-clicks. In Svelte (if that’s the tech, per design), use on:change for the file input and do not also bind on:dblclick anywhere. A simple fix is to ignore second clicks while a file dialog is already open or an upload is in progress. This will stop the file picker from popping up again.
Login Session Resets on Refresh: Currently, after logging in via the dashboard, if the page is refreshed, the user gets logged out and must log in again. This indicates the session state is not persisted. The backend uses a token-based auth (FastAPI HTTPBearer) where on successful login a token is generated and stored in an in-memory active_sessions dict, and returned to the client. However, the client likely only holds this token in a runtime variable. On refresh, that context is lost because the token isn’t stored or reused. Solution: Persist the session token on the client side and implement an auto-login or token check on page load. For example, store the token in localStorage or a cookie (HttpOnly cookie for security) when login succeeds. Then modify the dashboard initialization to look for an existing token and if found, attempt an auth check (e.g., call a /api/health or /api/status with the token). Alternatively, use a proper session cookie: set a cookie on login response (the FastAPI code currently just returns JSON with the token, but we could modify it to set an httponly cookie that the browser will send on refresh). In any case, the fix is to maintain the auth token across sessions. This will prevent the need to log in again after a simple refresh. The backend code is already equipped with a token validation (via HTTPBearer dependency), so leveraging that with a persistent token will solve the issue. Additionally, ensure the token has a reasonable expiration and that the UI handles expiration (perhaps redirect to login if a token is invalid).
UI Flow Audit: Aside from the above issues, the overall PDF upload flow should be: click upload -> select file -> show some progress or status -> extraction happens -> user sees confirmation or extracted concepts. Make sure the UI provides feedback (e.g., “Uploading…”, then “Extracting…” messages, maybe a spinner). The mention of double-click likely means users weren’t sure something happened, so they clicked again. Clear feedback can mitigate that. Also, after extraction, the new concepts should be visible (perhaps in a “Recent Concepts” list or the mesh view updates). If not updating, the UI might need to refresh that portion after extraction completes.
4. API Routes & Backend Logic Review
Existing Endpoints: The FastAPI backend (particularly in the Phase 1 and Phase 3 code) defines numerous routes for system operations. In Phase 1 (phase1_api_backend.py), we see endpoints like /api/health, /api/status for basic health checks, and various /api/lineage/... and /api/triggers/... routes for the evolution engine. These were the initial API set (engine metrics, lineage queries, trigger controls, etc.), and they should remain in the final system for completeness. Recently Added Endpoints: In the production integration (Phase 3), new endpoints were introduced for authentication and data ingestion: for example, /api/auth/login (login) and likely a logout route. Crucially, the PDF upload/extraction routes were missing in earlier code and appear to have been added during integration. The user’s testing showed a 404 on /api/upload
file-71z6jnjcbte3moymjnxfiq
, which means initially no such route was defined. The fix was to implement:
POST /api/upload: This endpoint should accept a PDF file (as multipart/form-data). The implementation should use fastapi.UploadFile to receive the file, save it to a temp directory (as was done manually before), and return a JSON with file_path and status. Ensure it saves in a path that the extraction function can access (the conversation snippet suggests using kha/tmp/ directory on disk). The route is now presumably defined in the Phase 3 secure dashboard code (or a related router). Double-check that the route path matches what the UI expects (the default was /api/upload). If the implementation accidentally mounted it at a different path (e.g. just /upload or under another router prefix), adjust it so the front-end and docs align.
POST /api/extract: This endpoint triggers the extraction process. It likely expects a JSON body with {"file_path": "...", "target": "prajna"} or "scholarsphere". On call, it should locate the file (the path from upload), run the appropriate ingestion routine: if target is "prajna", perform advanced concept extraction and memory injection; if "scholarsphere", perform archival storage (perhaps just log it in an archive or different database). Ensure this endpoint is implemented and awaits the background tasks properly. It should respond once extraction is done (or at least initiated), probably with a status message or the extracted summary. Given the asynchronous nature of PDF processing, one might consider doing this in a background task and immediately returning, but since the dashboard is expecting completion to show the data, a straightforward approach is fine (just be mindful of request timeouts for very large PDFs).
Wiring and Data Flow: Verify that the upload → extract → memory injection pipeline is end-to-end functional:
Upload: File is saved and path returned. (Test: hitting /api/upload via Swagger or curl should return JSON with status:"uploaded" and a valid file_path.)
Extract: Posting to /api/extract with that path and target runs the processing. This should invoke the PDF processing code. In the final integrated code, look at the phase3_complete_production_system.py or similar – it likely imports the AdvancedPDFProcessor or uses an internal function to handle this. Make sure that after processing, the code calls the Prajna memory API for target "prajna" or the archival logic for "scholarsphere". (If these are not implemented, it’s a to-do: e.g., implement a function to add concepts to ScholarSphere’s database or index.)
Response/Feedback: The /api/extract call might return immediately with a status like “extraction started” and the front-end uses websockets or polling to know when done. However, based on the current simpler design, it might just block and return once done. Either way, ensure the dashboard UI is updated accordingly – e.g., on success, it could automatically refresh the concept mesh or show a link to the new archive entry.
Backend FastAPI Code Audit: The production dashboard backend (phase3_production_secure_dashboard_complete.py) consolidates all routes. On review, all expected endpoints should be present and correctly secured:
Health check (likely /api/health – returns simple OK or version).
Login (/api/auth/login – returns token).
Logout (/api/auth/logout – probably removes the token from active_sessions).
Upload (/api/upload – as discussed, must be added; if it’s missing, add it).
Extract (/api/extract – ensure it’s there).
Concept Lineage and Metrics: endpoints from Phase 1 (e.g., /api/lineage/stats, /api/metrics/health, etc.). They should still function or be updated for the new data structures. For instance, after PDFs are ingested, the lineage ledger should track those concepts (the Phase 2/3 code introduced a ψ-LineageLedger for concept lifecycle). Verify that the lineage endpoints are now wired to that ledger (e.g., /api/lineage/concepts should fetch from the new ledger of concepts, not a stub). If any of these endpoints were lost during refactoring, reintroduce them.
Evolution Controls: Phase 3 includes endpoints or websocket events for approving or monitoring evolution strategies. The dashboard JS (phase3_dashboard_javascript_completion.js) references things like dashboard.approveProposal(...) – ensure there is a corresponding backend route (perhaps /api/evolution/approve or similar) that is called.
End-to-End Testing: It’s critical to simulate the full flow in a test environment:
Start the FastAPI app (phase3_complete_production_system.py or equivalent).
Use Swagger UI or curl to test /api/health (should return 200 OK).
Test login: POST to /api/auth/login with a valid user (the code likely has a self.users dict with usernames and hashed passwords – use one of those credentials). Confirm you get a token back.
With token, test the upload: POST a small PDF to /api/upload (as form-data). Expect a JSON with file path.
Then POST to /api/extract with that file path and "prajna". This should return a result (maybe a success message or the extracted data). Meanwhile, watch the server logs – you should see logs like “Advanced PDF processing…” and “✅ Advanced processing complete” as in the code. Also possibly logs from Prajna memory about concept added.
Finally, check Prajna’s state: perhaps call /api/lineage/concepts or /api/status to see if the new concepts are reflected, or simply interact with the dashboard UI (Concept Mesh graph should show new nodes, etc.).
Session and Security: The Phase 3 secure dashboard uses HTTPBearer for protected routes. Ensure that all state-changing routes (upload, extract, triggers, approvals) are protected, requiring a valid token. The login and health can be open. Check that the FastAPI Depends(HTTPBearer()) is applied where appropriate (it likely is in the code via a dependency on certain router or a decorator on the functions). Also verify CORS middleware is enabled if the front-end is separate domain; the code imports CORS middleware, so configure allowed origins as needed. Summary of Required Fixes/Enhancements:
Implement missing /api/upload and /api/extract routes (as per above) so that the front-end flow works (the user’s 404 confirms this was needed
file-71z6jnjcbte3moymjnxfiq
 – it should now be resolved in the integrated code).
Fix the double-click file input issue on the front-end by adjusting event handling (ensure one file-open per click).
Persist login sessions by storing the token client-side (or using cookies) to avoid logout on refresh.
Improve concept extraction by using more advanced NLP techniques (to address only 3 concepts being captured).
After extraction, actively inject concepts into Prajna’s Concept Mesh (calling the appropriate Prajna memory API) rather than just logging or saving to JSON.
Verify all Phase 1/2 functionality (triggers, lineage ledger, metrics) is still wired in Phase 3. For instance, the ψ‑LineageLedger (concept lifecycle tracking) should be updating when new concepts from PDFs are added – check the code in phase1_psi_lineage_ledger.py and Phase 2 ledger fixes to ensure they listen to new concept events. If not, emit events when adding concepts so the ledger records them.
File paths and names: double-check where files are saved (Windows vs Linux paths). The code uses Windows-style paths in some places (e.g., in main() of AdvancedDataProcessor, the data directory is a Windows path). Make sure in a deployment environment those paths are configured via config (perhaps use production_config.json).
By addressing these points, the TORI system will be robust and ready for “self-evolution” with live concept streaming. The PDF ingestion pipeline will become reliable: a user can upload a technical PDF, the system will extract a rich set of concepts and immediately inject them into Prajna’s knowledge graph, and the dashboard will reflect this new knowledge (both in the concept mesh visualization and in any archive/ledger). Moreover, the login and file upload UX will be smooth – no unintended logouts or confusing double dialogs – allowing users to interact continuously. Key Files & Locations:
Concept Extraction: phbeforephases/advanced_pdf_processor.py – contains PDF parsing and _extract_key_concepts logic.
Prajna Memory Integration: prajna/memory/ modules (e.g. concept_mesh_api.py, context_builder.py) – where concepts should be added; and phases/phase3_complete_production_system.py (or similar) – where the API calls the extraction and then uses Prajna’s API.
Upload/Extract API: Implemented in the FastAPI app (see phase3_production_secure_dashboard_complete.py for auth and possibly an included router, or phase3_complete_production_system.py). If not easily found, it may need adding – likely as @app.post("/api/upload") and @app.post("/api/extract") in the main app file.
Dashboard Frontend: The SvelteKit front-end (not fully provided here, except for a snippet) – ensure in the Svelte code that after file selection (<input type="file"), an upload is triggered via fetch('/api/upload'), and then extraction via fetch('/api/extract'). The double-click issue fix lies in this area.
Authentication: In phase3_production_secure_dashboard_complete.py – look at the login() function and UserSession handling around line 200+ and the usage of self.active_sessions. That is where token generation and storage happens. Also see how Depends(HTTPBearer) is used for protected endpoints. This file is central to the backend logic in production mode.
Lineage & Evolution: phase1_conditional_trigger_engine.py, phase1_psi_lineage_ledger.py, and their Phase 2/3 counterparts define the logic for concept evolution triggers and ledger. These should be integrated into the main system (likely instantiated in the production system main file). Verify their methods are invoked – e.g., the trigger engine should be checking conditions periodically or on certain events; the monitoring system (phase3_production_monitoring_system.py) might schedule these. Ensure the dashboard JS (which updates metrics and shows proposals) is receiving data from these (possibly via /api/metrics/* endpoints or a websocket feed).
With these fixes and confirmations, the TORI system’s pipeline – from PDF ingestion to concept extraction to knowledge integration and user dashboard – will be complete and robust. The system will then be ready for continuous self-improvement cycles, with live data feeding Prajna and the evolution engine having rich knowledge to work with.