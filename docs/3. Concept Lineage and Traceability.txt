3. Concept Lineage and Traceability
The modifications above ensure that every concept in the final list carries its lineage information, enabling traceability:
Origin Tracking: Each ConceptTuple.originDocs entry tells us which document the concept came from, how many times it appeared, and even includes a snippet of the original text. This way, one can trace a concept back to the exact source context (e.g. Document A, Introduction section, 2 occurrences).
Merging Lineage: The mergedFrom array captures which raw extracted terms were merged into a single concept. For example, if “AI” and “Artificial Intelligence” were clustered together, the resulting ConceptTuple might have name: "Artificial Intelligence" (as the chosen representative) and mergedFrom: ["AI", "Artificial Intelligence"]. This tells us that those two terms were considered the same underlying concept.
Score Evolution: In debug mode, the scoreEvolution field provides a step-by-step breakdown of the scoring calculation for a concept. For instance, one might see that a concept’s base frequency contributed 0.2 to the score, then centrality raised it to 0.5, etc., culminating in the final composite. This is useful for developers to understand why a concept got a high or low score.
Cluster Trace: The clusterId and clusterTrace indicate how the concept was formed via clustering. clusterId is an identifier for the cluster group, and clusterTrace.algorithm records which clustering method was used (e.g. "kmeans" or "hdbscan"). In a more complex scenario, if multiple clustering passes or algorithms were tried, this field could store the history (e.g. cluster ID under spectral vs HDBSCAN, etc.). In our implementation we just record the final method and ID.
All these additions are stored directly in the ConceptTuple structure, so they can be logged or displayed. The code above writes a JSON file (concept_lineage_debug.json) when in debug mode – this file will contain an array of all ConceptTuple objects with full details. This can be loaded into analysis tools or inspected manually to trace concept origins, merges, and scoring. In CSV form, similar information (e.g. listing concept, source doc, original terms) could be produced if needed. By having this lineage readily available, developers and analysts can trace every concept from the final output back to its origin in the raw text, see how it was combined with others, and verify the scoring, greatly increasing transparency and debuggability of the system.