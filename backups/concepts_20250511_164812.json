[
  {
    "name": "Software system Business logiccontext model User model",
    "embedding": [
      0.4163942337036133,
      0.2275676429271698,
      0.2275676429271698,
      0.1133134588599205,
      0.0035971044562757015,
      -0.3909502625465393,
      -0.06483326852321625,
      -0.06483326852321625,
      -0.02390984259545803,
      0.05488619953393936,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "context": "EASE 2025, 17\u201320 June, 2025, Istanbul, T\u00fcrkiye Gaspar-Figueiredo et al.\nSoftware System\nBusiness LogicContext Model\nUser Model\nPlatform Model\nEnvironment ModelIntelligent UI Adaptor\nUser PlatformContext of Use\nMonitorExternal Sources\nData Information\nKnowledge WisdomUser Interface\nAction\nState\nRewardUI ModelAdaptive Capabilities\nHuman Feedback Module\nAdaptation \nExamplesAdaptation Manager\nReinforcement \nLearning AgentOffline Feedback \nCollectorPreference Model \u2026\u2026\n\u2026 PreferencesReward Model\nPredictive \nHCI modelsHuman \nFeedback\nAdaptation \nEngine\nFigure 1: Extended intelligent UI adaptation framework from [ 1]. Human Feedback Module and Reward Model are the main\ncontributions in this paper.\nbeyond a generic adaptation strategy, creating a cooperative in-\nteraction loop where the agent continuously refines its decisions\nbased on specific user input. By coupling baseline HCI metrics with\nhuman feedback, we aim to address the gap in intelligent UI adap-\ntation: the need for interfaces that are both technically efficient and\nmeaningfully aligned with the human aspects of interaction [1].\n3.2.3 Implementation .We used the replication package pro-\nvided by Gaspar-Figueiredo et al. [ 16], which utilizes OpenAI Gym [ 7]\nto offer a structured environment for RL implementations. Using\nOpenAI Gym, we defined the system\u2019s states ( Context Model andUI\nModel ), actions ( Adaptation Capabilities ), and reward mechanisms.\nThese elements ensure compatibility with RL algorithms such as\nQ-Learning [ 16] and Monte Carlo Tree Search [ 8]. The extended\nframework is available here: https://github.com/RESQUELAB/RL-\nBased-Framework\n4 Experimental Study\nFollowing the GQM template for goal definition [ 10], the goal of\nthis study is to analyze the integration of Human Feedback from\nindividual users into a RL-based UI adaptation approach with the\npurpose of assessing its impact as regards adapting UIs with re-\nspect to its ability to improve the user experience from the point-\nof-view of both novice developers and researchers interested in\nadaptive user interfaces.\nThe study involves Master\u2019s students in Computer Science at\ntheUniversitat Polit\u00e8cnica de Val\u00e8ncia (UPV) , interacting with UIs\nfrom two domains: an e-learning system and a trip-planning system .\nThese domains test UI adaptation and show how domain specificity\ninfluences user feedback and adaptations.\n4.1 Research Question and Hypothesis\nWe aim to investigate the extent to which incorporating human\nfeedback into RL-based UI adaptations affects the user experience\nacross different domains. User experience is operationalized interms of user satisfaction and user engagement (see the next sub-\nsection for details). The research question (RQ) and hypotheses\nguiding the investigation are as follows:\nRQ1 : How does incorporating human feedback into a reinforce-\nment learning-based UI adaptation affect the overall user experi-\nence?\n\u2022\ud835\udc3b\ud835\udc5b1: There is no significant difference in user satisfaction\nbetween AUIs that use predictive HCI models with person-\nalized human feedback and non-adaptive UIs.\n\u2022\ud835\udc3b\ud835\udc5b2: There is no significant difference in user engagement\nbetween AUIs that use predictive HCI models with person-\nalized human feedback and non-adaptive UIs.\nThe statistical analysis aims to reject these hypotheses and accept\nthe alternative ones ( e.g.,\ud835\udc3b\ud835\udc4e1=\u00ac\ud835\udc3b\ud835\udc5b1). These two-sided hypotheses\ndo not postulate any effect from different adaptation strategies.\nNon-adaptive interfaces serve as a baseline to evaluate the im-\npact of RL-based UI adaptations, isolating the contributions of RL\nmechanisms and human feedback. This approach also reflects real-\nworld applications where static designs are common. Prior work\nshowed no statistically significant difference among Adaptive and\nnon-adaptive approaches, highlighting the need for further research\non how RL-based adaptations and human feedback influence user\nexperience.\n4.2 Variables\nThis section outlines the variables, measurement scales, and their\noperationalization.\n4.2.1 Independent Variables .The main independent variable\nis the UI adaptation strategy , a nominal variable with two levels:\nAdaptive UI with human feedback (Adaptive) and Non-Adaptive\nUI (NA). The secondary independent variable is the application\ndomain , a nominal variable with two levels: Trips (a travel planning\napplication) and Courses (an e-learning system).\n4.2.2 Dependent Variables .The primary dependent variable is\nUX, defined by ISO 9241-210: 2010 as \"a person\u2019s perceptions and",
    "passage_embedding": [
      0.5567111968994141,
      0.3653417229652405,
      0.24356114864349365,
      0.08698612451553345,
      0.24356114864349365,
      0.1565750241279602,
      0.19136947393417358,
      0.1739722490310669,
      0.20876669883728027,
      0.0,
      0.1565750241279602,
      0.06958889961242676,
      0.12178057432174683,
      0.13917779922485352,
      0.05219167470932007,
      0.10438334941864014,
      0.03479444980621338,
      0.03479444980621338,
      0.01739722490310669,
      0.08698612451553345,
      0.0,
      0.05219167470932007,
      0.05219167470932007,
      0.08698612451553345,
      0.03479444980621338,
      0.0,
      0.08698612451553345,
      0.08698612451553345,
      0.03479444980621338,
      0.0,
      0.08698612451553345,
      0.03479444980621338,
      0.0,
      0.05219167470932007,
      0.05219167470932007,
      0.0,
      0.06958889961242676,
      0.03479444980621338,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.05219167470932007,
      0.05219167470932007,
      0.06958889961242676,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.06958889961242676,
      0.01739722490310669,
      0.0,
      0.03479444980621338,
      0.01739722490310669,
      0.0,
      0.06958889961242676,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.06958889961242676,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.05219167470932007,
      0.01739722490310669,
      0.01739722490310669,
      0.06958889961242676,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.03479444980621338,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.05219167470932007,
      0.05219167470932007,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.06958889961242676,
      0.01739722490310669,
      0.03479444980621338,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.06958889961242676,
      0.08698612451553345,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.05219167470932007,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.05219167470932007,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.03479444980621338,
      0.0,
      0.01739722490310669,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03479444980621338,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.03479444980621338,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.05219167470932007,
      0.03479444980621338,
      0.05219167470932007,
      0.05219167470932007,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.03479444980621338,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.03479444980621338,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.05219167470932007,
      0.03479444980621338,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.01739722490310669,
      0.03479444980621338,
      0.01739722490310669,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "cluster_members": [
      3,
      4,
      5,
      6,
      8
    ],
    "resonance_score": 0.4423690140247345,
    "narrative_centrality": 0.0
  },
  {
    "name": "Neglecting individualized human feedback in adaptive systems Sources . The adaptation manager orchestrates the adaptation process,",
    "embedding": [
      0.29582446813583374,
      -0.02904289774596691,
      -0.02904289774596691,
      -0.36883533000946045,
      0.3431633710861206,
      0.01419290155172348,
      0.2904137372970581,
      0.2904137372970581,
      -0.19470256567001343,
      -0.16952216625213623,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "context": "EASE 2025, 17\u201320 June, 2025, Istanbul, T\u00fcrkiye Gaspar-Figueiredo et al.\ncapturing user preferences and was solely evaluated in simulated\nenvironments, limiting its applicability to real-world interactions.\nOur initial extension [ 15] introduced human feedback but applied\na single HF model across all users, failing to account for individual\npreferences and resulting in suboptimal adaptation outcomes.\nNeglecting individualized human feedback in adaptive systems\ncan result in user interfaces that fail to respond effectively to actual\nuser preferences. Without direct user input, RL agents must rely on\ngeneralized data or simulated feedback, which often fails to capture\nindividual behaviors and contextual requirements. This limitation\nreduces the system\u2019s ability to fine-tune adaptations based on real-\nworld interactions, potentially missing opportunities for deeper\npersonalization [ 5]. Addressing this gap requires leveraging human\nfeedback mechanisms to refine RL agents at an individual level,\nensuring that adaptive UI strategies align more closely with user\npreferences and ultimately improve user satisfaction..\nIn this paper, we therefore enhance the RL-based framework for\nUI adaptations proposed by Gaspar-Figueiredo et al. [ 16] by inte-\ngrating human feedback directly into the learning and adaptation\nprocess, enabling users to shape adaptations in real-time. Addi-\ntionally, to evaluate the effectiveness of this approach, we report\nthe results of an empirical study aimed at evaluating the impact\nof Human Feedback on RL-based UI adaptations and their effect\non user experience, using non-adaptive interfaces as a baseline for\ncomparison. Since non-adaptive systems provide a fixed and con-\nsistent experience, they serve as a suitable benchmark for assessing\nthe effectiveness of RL-based AUIs.\nThis paper is organized as follows: Section 2 review existing\nempirical studies on adaptive user interfaces. Section 3 provides an\noverview of the original RL-based UI adaptation framework and de-\ntails our extension to incorporate human feedback at an individual\nlevel (by each user). Section 4 describes the design and execution of\nthe empirical study, while Section 5 presents the results and explores\ntheir implications for research and practice. Section 6 addresses\npotential threats to the validity of the findings. Finally, Section 7\nconcludes the paper and outlines future research directions.\n2 Related Work\nThe Software Engineering (SE) and Human-Computer Interaction\n(HCI) communities communities have made significant progress\nin advancing the design and evolution of AUIs by leveraging AI\ntechniques. Despite positive results in some studies [ 39], challenges\nremain, including unpredictability, detrimental adaptations, inaccu-\nrate interpretation of user needs, and limited user involvement. A\nfundamental aspect of applying RL to AUIs is defining an appro-\npriate reward function, which is challenging, especially when user\ngoals are ambiguous or the impact of actions is unclear.\nPrior research has explored various RL approaches for UI adapta-\ntion. Langerak et al. [ 23,24]proposed a multi-agent RL framework.\nVidmanov and Alfimtsev [35] integrated a usability reward model.\nTodi et al. [32] employed Monte Carlo Tree Search (MCTS) with\npredictive HCI models. The authors in [16] integrated predictive\nHCI models into a RL-based approach, demonstrating RL\u2019s poten-\ntial to automate UI adaptation based on usability metrics. However,\nthis study relied on simulations, failing to capture the complexities\nand variability of real-world user behavior.Prior research has explored various RL approaches for UI adap-\ntation. Langerak et al. [ 23,24] proposed a multi-agent RL frame-\nwork in which a user agent learns to interact with the UI while\nan interface agent learns to adapt it. Vidmanov and Alfimtsev [ 35]\nextended this approach by integrating a usability reward model,\nenabling cooperative adaptation of UI elements to enhance user\nexperience. Similarly, Todi et al. [ 32] employed Monte Carlo Tree\nSearch (MCTS) combined with predictive HCI models to simulate\nand evaluate UI adaptation strategies. By leveraging a pretrained\nvalue network, their approach mitigated the computational cost of\nonline simulations while maintaining a high success rate.\nSimilarly, in [ 16], the authors integrated predictive HCI models\ninto a RL-based approach for AUIs. This study trained and evaluated\nRL agents in a simulated environment to assess their effectiveness in\nadapting UIs, specifically aiming to maximize user engagement. The\nresults demonstrated RL\u2019s potential to automate UI adaptation based\non general-purpose usability metrics. However, a major limitation\nof this study was its reliance on simulations, without involving\nuser interactions. Consequently, the study was unable to capture\nthe complexities and variability of user behavior that occur in real-\nworld scenarios, where individual preferences and interactions can\nvary widely.\nTo the best of our knowledge, no prior work has applied Rein-\nforcement Learning with Human Feedback (RLHF) to AUIs. Build-\ning on this foundation, we extended the framework [ 16] by incor-\nporating human feedback, distinguishing our approach from prior\nwork by explicitly integrating user preferences into the adaptation\nprocess. While previous studies have explored RL-based UI adap-\ntation through predictive models and automated agents, our work\nemphasizes direct human feedback to refine adaptation strategies,\nthereby aligning the adaptations more closely with user needs.\nIn a previous empirical study [ 15], we used a general model,\ntrained solely on feedback provided by the experimenter (when\ntraining the RL models), to incorporate human feedback into the\nadaptation process. This approach aimed to assess whether user\nfeedback, even provided only by the experimenters, could enhance\nuser satisfaction and user engagement when interacting with AUIs.\nSpecifically, the study compared AUIs which used predictive HCI\nmodels and AUIs which used predictive HCI models augmented\nwith human feedback to non-adaptive interfaces. The findings sug-\ngested a potential for human feedback to improve user satisfaction\nand engagement, despite lacking statistical significance. However,\nthe study had limitations, primarily due to the use of a general\nfeedback model that may have been insufficiently sensitive to in-\ndividual user preferences. The experimenter\u2019s preferences, which\nshaped the model, may not have accurately reflected the diversity\nof the participant base.\nThis paper addresses the limitations of using a general prefer-\nence model by incorporating personalized RL agents trained by\neach user. Unlike the previous study [ 15], where a general model\nwas trained based on experimenter-provided feedback, we now\nintroduce models that learn directly from individual users, allowing\nthe system to adapt more precisely to their unique preferences\nand needs. By comparing AUIs with personalized feedback models\nto non-adaptive interfaces, this study aims to deepen our under-\nstanding of how user-specific adaptations impact user satisfaction\nand engagement. This progression illustrates the evolution of the",
    "passage_embedding": [
      0.5583248138427734,
      0.3398498594760895,
      0.3398498594760895,
      0.1213749572634697,
      0.21847492456436157,
      0.08496246486902237,
      0.10923746228218079,
      0.1213749572634697,
      0.15778744220733643,
      0.0,
      0.0,
      0.16992492973804474,
      0.1335124522447586,
      0.09709995985031128,
      0.06068747863173485,
      0.02427498996257782,
      0.01213749498128891,
      0.04854997992515564,
      0.04854997992515564,
      0.01213749498128891,
      0.02427498996257782,
      0.04854997992515564,
      0.1335124522447586,
      0.02427498996257782,
      0.04854997992515564,
      0.04854997992515564,
      0.02427498996257782,
      0.04854997992515564,
      0.1213749572634697,
      0.0,
      0.02427498996257782,
      0.07282496988773346,
      0.10923746228218079,
      0.06068747863173485,
      0.06068747863173485,
      0.0,
      0.08496246486902237,
      0.10923746228218079,
      0.01213749498128891,
      0.03641248494386673,
      0.0,
      0.06068747863173485,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.08496246486902237,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.0,
      0.08496246486902237,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03641248494386673,
      0.0,
      0.0,
      0.0,
      0.03641248494386673,
      0.01213749498128891,
      0.0,
      0.03641248494386673,
      0.01213749498128891,
      0.07282496988773346,
      0.03641248494386673,
      0.03641248494386673,
      0.02427498996257782,
      0.04854997992515564,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.04854997992515564,
      0.0,
      0.07282496988773346,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.01213749498128891,
      0.04854997992515564,
      0.04854997992515564,
      0.07282496988773346,
      0.01213749498128891,
      0.04854997992515564,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.06068747863173485,
      0.01213749498128891,
      0.08496246486902237,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.03641248494386673,
      0.06068747863173485,
      0.06068747863173485,
      0.0,
      0.01213749498128891,
      0.0,
      0.02427498996257782,
      0.0,
      0.01213749498128891,
      0.02427498996257782,
      0.0,
      0.03641248494386673,
      0.01213749498128891,
      0.01213749498128891,
      0.03641248494386673,
      0.01213749498128891,
      0.06068747863173485,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.03641248494386673,
      0.01213749498128891,
      0.04854997992515564,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.04854997992515564,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.02427498996257782,
      0.0,
      0.01213749498128891,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.04854997992515564,
      0.01213749498128891,
      0.02427498996257782,
      0.04854997992515564,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.03641248494386673,
      0.03641248494386673,
      0.03641248494386673,
      0.04854997992515564,
      0.03641248494386673,
      0.0,
      0.0,
      0.0,
      0.03641248494386673,
      0.01213749498128891,
      0.02427498996257782,
      0.0,
      0.01213749498128891,
      0.0,
      0.02427498996257782,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.01213749498128891,
      0.03641248494386673,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.04854997992515564,
      0.02427498996257782,
      0.02427498996257782,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.04854997992515564,
      0.02427498996257782,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.01213749498128891,
      0.02427498996257782,
      0.03641248494386673,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03641248494386673,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.03641248494386673,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.02427498996257782,
      0.03641248494386673,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.03641248494386673,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.03641248494386673,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.03641248494386673,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.02427498996257782,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.02427498996257782,
      0.02427498996257782,
      0.0,
      0.02427498996257782,
      0.03641248494386673,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.02427498996257782,
      0.03641248494386673,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.03641248494386673,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.03641248494386673,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.01213749498128891,
      0.0,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.02427498996257782,
      0.02427498996257782,
      0.02427498996257782,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.01213749498128891,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "cluster_members": [
      1,
      2
    ],
    "resonance_score": 0.25177252292633057,
    "narrative_centrality": 0.0
  },
  {
    "name": "Integrating human feedback into a reinforcement Learning-based framework for adaptive user interfaces Daniel gaspar-figueiredo",
    "embedding": [
      0.2611265778541565,
      -0.321481317281723,
      -0.321481317281723,
      -0.16905714571475983,
      0.14170032739639282,
      0.3799724876880646,
      -0.4739530086517334,
      -0.4739530086517334,
      0.2746832072734833,
      -0.08579138666391373,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "context": "Integrating Human Feedback into a Reinforcement\nLearning-Based Framework for Adaptive User Interfaces\nDaniel Gaspar-Figueiredo\nUniversitat Polit\u00e8cnica de Val\u00e8ncia and Instituto\nTecnol\u00f3gico de Inform\u00e1tica\nValencia, Spain\ndagasfi@epsa.upv.esMarta Fern\u00e1ndez-Diego\nUniversitat Polit\u00e8cnica de Val\u00e8ncia\nValencia, Spain\nmarferdi@omp.upv.es\nSilvia Abrah\u00e3o\nUniversitat Polit\u00e8cnica de Val\u00e8ncia\nValencia, Spain\nsabrahao@dsic.upv.esEmilio Insfran\nUniversitat Polit\u00e8cnica de Val\u00e8ncia\nValencia, Spain\neinsfran@dsic.upv.es\nAbstract\nAdaptive User Interfaces (AUI) play a crucial role in modern soft-\nware applications by dynamically adjusting interface elements to\naccommodate users\u2019 diverse and evolving needs. However, existing\nadaptation strategies often lack real-time responsiveness. Rein-\nforcement Learning (RL) has emerged as a promising approach\nfor addressing complex, sequential adaptation challenges, enabling\nadaptive systems to learn optimal policies based on previous adapta-\ntion experiences. Although RL has been applied to AUIs,integrating\nRL agents effectively within user interactions remains a challenge.\nIn this paper, we enhance a RL-based Adaptive User Interface\nadaption framework by incorporating personalized human feed-\nback directly into the leaning process. Unlike prior approaches that\nrely on a single pre-trained RL model, our approach trains a unique\nRL agent for each user, allowing individuals to actively shape their\npersonal RL agent\u2019s policy, potentially leading to more personal-\nized and responsive UI adaptations. To evaluate this approach, we\nconducted an empirical study to assess the impact of integrating\nhuman feedback into the RL-based Adaptive User Interface adap-\ntion framework and its effect on User Experience (UX). The study\ninvolved 33 participants interacting with AUIs incorporating hu-\nman feedback and non-adaptive user interfaces in two domains:\nan e-learning platform and a trip-planning application. The results\nsuggest that incorporating human feedback into RL-driven adapta-\ntions significantly enhances UX, offering promising directions for\nadvancing adaptive capabilities and user-centered design in AUIs.\nCCS Concepts\n\u2022Software and its engineering \u2192Software design engineer-\ning;\u2022Human-centered computing \u2192User interface design ;Em-\npirical studies in HCI ;\u2022Computing methodologies \u2192Rein-\nforcement learning .\nKeywords\nAdaptive Systems, Adaptive User Interfaces, User Experience, Rein-\nforcement Learning, Human Feedback.\n1 Introduction\nAdaptive systems and Adaptive User Interfaces (AUI) address usabil-\nity challenges by dynamically adjusting interface elements [ 3,34].Existing adaptation approaches, including recommendation sys-\ntems and configurable UIs [ 18,24,36], often struggle with complex,\nlong-term adaptation and holistic interface optimization. Most ex-\nisting research has focused on adapting isolated UI elements, such\nas menus [ 9,29,32], rather than holistically optimizing the entire\ninterface. This limitation highlights the need for approaches capable\nof handling the inherent complexity of adapting the entire interface\ndynamically. Furthermore, many existing adaptation strategies rely\non pre-defined rules or offline models, which lack the flexibility to\nsupport real-time user interactions.\nRecent advancements in Artificial Intelligence (AI), particularly\nMachine Learning (ML), offer promising avenues to support more\neffective UI adaptation. Among these, Reinforcement Learning (RL)\nhas emerged as a robust solution for managing the complexities of\nadaptive interfaces. Unlike traditional ML approaches that optimize\nspecific UI features using static adaptation models (or do not learn\nfrom past actions over time), RL enables an agent to learn adaptive\npolicies that evolve over time by continuosly refining its decisions\nbased on past interactions, which can be useful to guide changes\nacross the entire interface. By modeling the UI adaptation problem\nas a sequential decision-making process, an RL agent can optimize\nkey quality attributes, such as User Experience (UX), over extended\ninteraction periods, by maximizing cumulative rewards that reflect\noverall user experience.\nHowever, designing effective RL-based UI adaptations requires\ncareful consideration of the reward function, which quantifies the\nsuccess of each adaptation and guides the agent toward beneficial\nadjustments. A poorly designed reward function can lead to sub-\noptimal behaviors, where the agent prioritizes factors that do not\nalign with user needs. To address this problem, a new and growing\narea of RL research explores the integration of human feedback\n(HF), where humans directly influence the agent\u2019s learning process\nby providing input on its decisions. Human feedback offers a mech-\nanism to refine the reward signal, ensuring that the agent\u2019s learned\nadaptations align more closely with user preferences. Despite its\npotential, effectively incorporating human feedback into RL-based\nadaptation remains an open challenge.\nBuilding upon the RL-based UI adaptation framework proposed\nby Gaspar-Figueiredo et al. [ 16], we aim to address its limitations\nby incorporating human feedback directly into the learning and\nadaptation process. The original framework lacked mechanisms forarXiv:2504.20782v1  [cs.HC]  29 Apr 2025",
    "passage_embedding": [
      0.44172611832618713,
      0.25767356157302856,
      0.33129459619522095,
      0.11043152958154678,
      0.16564729809761047,
      0.23926831781864166,
      0.07362101972103119,
      0.22086305916309357,
      0.18405254185199738,
      0.0,
      0.036810509860515594,
      0.07362101972103119,
      0.14724203944206238,
      0.018405254930257797,
      0.12883678078651428,
      0.0,
      0.018405254930257797,
      0.0,
      0.14724203944206238,
      0.0,
      0.036810509860515594,
      0.09202627092599869,
      0.036810509860515594,
      0.16564729809761047,
      0.0,
      0.0,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.0,
      0.05521576479077339,
      0.018405254930257797,
      0.11043152958154678,
      0.11043152958154678,
      0.0,
      0.05521576479077339,
      0.05521576479077339,
      0.018405254930257797,
      0.05521576479077339,
      0.0,
      0.018405254930257797,
      0.036810509860515594,
      0.16564729809761047,
      0.018405254930257797,
      0.11043152958154678,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.05521576479077339,
      0.05521576479077339,
      0.05521576479077339,
      0.018405254930257797,
      0.0,
      0.0,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.036810509860515594,
      0.07362101972103119,
      0.018405254930257797,
      0.0,
      0.0,
      0.05521576479077339,
      0.0,
      0.0,
      0.07362101972103119,
      0.0,
      0.0,
      0.0,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.09202627092599869,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.05521576479077339,
      0.036810509860515594,
      0.036810509860515594,
      0.07362101972103119,
      0.05521576479077339,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.05521576479077339,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.0,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.036810509860515594,
      0.05521576479077339,
      0.07362101972103119,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.05521576479077339,
      0.036810509860515594,
      0.036810509860515594,
      0.07362101972103119,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.07362101972103119,
      0.07362101972103119,
      0.07362101972103119,
      0.07362101972103119,
      0.07362101972103119,
      0.018405254930257797,
      0.036810509860515594,
      0.036810509860515594,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.05521576479077339,
      0.018405254930257797,
      0.036810509860515594,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.07362101972103119,
      0.036810509860515594,
      0.05521576479077339,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.05521576479077339,
      0.036810509860515594,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.018405254930257797,
      0.07362101972103119,
      0.07362101972103119,
      0.018405254930257797,
      0.018405254930257797,
      0.05521576479077339,
      0.036810509860515594,
      0.05521576479077339,
      0.05521576479077339,
      0.018405254930257797,
      0.05521576479077339,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.05521576479077339,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.05521576479077339,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.036810509860515594,
      0.036810509860515594,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.036810509860515594,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797,
      0.018405254930257797
    ],
    "cluster_members": [
      0
    ],
    "resonance_score": 0.0,
    "narrative_centrality": 0.0
  },
  {
    "name": "Table 3: fixed effects estimates of the lmms. User satisfaction user engagement Model assumptions were evaluated for both dependent variables",
    "embedding": [
      0.33828049898147583,
      -0.07494769245386124,
      -0.07494769245386124,
      -0.05764015391469002,
      -0.5788521766662598,
      0.12602682411670685,
      -0.10452044755220413,
      -0.10452044755220413,
      -0.15386244654655457,
      0.688864529132843,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "context": "EASE 2025, 17\u201320 June, 2025, Istanbul, T\u00fcrkiye Gaspar-Figueiredo et al.\nTable 3: Fixed Effects Estimates of the LMMs.\nUser Satisfaction User Engagement\nPredictors Estimates Lower CI Upper CI p-value Estimates Lower CI Upper CI p-value\n(Intercept) 6.50 5.85 7.14 <0.001 *** 3.27 2.90 3.64 <0.001 ***\ndomain [trips] -0.06 -0.29 0.17 0.600 -0.07 -0.25 0.12 0.458\ntechnique [Non-Adaptive] -0.97 -1.20 -0.74 <0.001 *** -0.23 -0.41 -0.04 0.016 *\ngroup [2] 0.88 -0.04 1.79 0.060 0.45 -0.06 0.96 0.085\ngroup [3] 0.64 -0.24 1.53 0.152 0.17 -0.33 0.66 0.504\ngroup [4] 0.29 -0.55 1.13 0.498 0.11 -0.36 0.58 0.631\nNote: * p <0.05; ** p <0.01; *** p <0.001\n5.2 Hypotheses Testing\nModel assumptions were evaluated for both dependent variables\n(User Satisfaction andUser Engagement ). The Shapiro-Wilk test was\nused to confirm the normality of residuals, indicating no significant\ndeviation from normality ( \ud835\udc5d>0.05). Homogeneity of variances\nwas assessed using Levene\u2019s test, with results ( \ud835\udc5d>0.05) verifying\nthat variances were consistent across conditions. These findings\nconfirm that the assumptions required for conducting the Linear\nMixed Model analysis were satisfactorily met.\nFollowing the descriptive analysis and assumption testing, we\nbuilt a Linear Mixed Model for each dependent variable. The results\nof the fixed effects are shown in Table 3. On the one hand, the analy-\nsis showed that the technique used had a significant impact on User\nSatisfaction , with non-adaptive technique resulting in lower satis-\nfaction levels (Estimate = \u22120.97,\ud835\udc5d<0.001). This finding supports\nthe hypothesis that users would express higher satisfaction with\nadaptive techniques compared to the non-adaptive one. Conversely,\nthe domain variable did not exhibit a significant effect (Estimate\n=\u22120.06,\ud835\udc5d=0.602), indicating that User satisfaction did not sig-\nnificantly differ between the Courses and Trips domains. Since\ngroup was confounded with carryover and the technique*period\ninteraction, we can conclude that none of these variables are sig-\nnificant. Thus, there is no carryover effect between the techniques.\nOn the other hand, for the engagement model, the technique used\nalso demonstrated a significant effect, with the non-adaptive tech-\nnique associated with a lower engagement level (Estimate = \u22120.23,\n\ud835\udc5d=0.016). This result supports the hypothesis that adaptive tech-\nniques would lead to higher engagement levels compared to the\nnon-adaptive one. As with satisfaction, the domain variable did not\nproduce a statistically significant effect on engagement (Estimate =\n\u22120.07,\ud835\udc5d=0.458), suggesting that engagement levels were consis-\ntent across both the Courses and Trips domains. Similarly to User\nSatisfaction , there is no carryover effect between the techniques.\nTable 4 shows the mean random effects variance ( \ud835\udefc2) of the\nmodel and random intercept variance ( \ud835\udf0f00) which indicates how\nmuch subjects differ from each other. The ICC (Intraclass Corre-\nlation Coefficient) of 76% and 55% indicates good and moderate\nreliability [ 20] for User Satisfaction andUser Engagement respec-\ntively, i.e. a single individual produces consistent measurements.\nIn other words, it means more difference among individuals than\nwithin them, justifying the individual differences modeled by ran-\ndom effects. Besides, the \ud835\udc452values provide further insight into\nthe explained variance for each model. For User Satisfaction , the\nConditional \ud835\udc452was 0.828, indicating that 82.8%of the variance isexplained by both fixed and random factors, with the Marginal \ud835\udc452\nat0.281, suggesting that the fixed effects alone account for 28.1%of\nthis variance. This points out to a the role of individual differences\ninUser Satisfaction . Similarly, for User Engagement , the Conditional\n\ud835\udc452was 0.605, showing that 60.5%of the variance is explained by\nboth fixed and random effects, while the Marginal \ud835\udc452of0.113indi-\ncates that fixed factors account for only 11.3%of the variance. This\nfinding emphasizes the greater influence of individual differences\non user satisfaction relative to user engagement.\nTable 4: Random Effects of the LMMs.\nRandom Effects User Satisfaction User Engagement\n\ud835\udefc20.21 0.14\n\ud835\udf0f00 0.68 user 0.17 user\nICC 0.76 0.55\nN 33user 33user\nObservations 66 66\nMarginal\ud835\udc4520.281 0.113\nConditional \ud835\udc4520.828 0.605\nIn summary, these findings suggest that the adaptation strategy\nused in this experiment, namely Adaptive UI with individualized\nhuman feedback which create a unique RL Agent for each user,\nsignificantly enhances both User Satisfaction andUser Engagement ,\nindependent of domain, thereby supporting the hypothesis that\nthis adaptation technique positively impact user experience.\n5.3 Discussion\nThis study provides valuable insights into individualized prefer-\nence models in AUIs. Differing from our previous experiment [ 15],\nwhich found no significant differences between adaptive and non-\nadaptive interfaces, the current study underscores the value of\nadaptation strategies informed by individual user data. Unlike the\nearlier study, which used a generalized human feedback model,\ntrained by an experimenter for all participants, the present study\nemployed individualized preference models, leveraging both pre-\ndictive HCI models and human feedback to train a unique RL agent\nfor each user. This resulted in statistically significant improvements\nin user satisfaction and engagement, emphasizing the effectiveness\nof personalized adaptation strategies.\nTo the best of our knowledge, a broader insight is the absence of\nstandardized methodologies to address the core challenges associ-\nated with AUIs. Key challenges include defining the AUI problem,",
    "passage_embedding": [
      0.5391918420791626,
      0.11982040107250214,
      0.22965577244758606,
      0.12980544567108154,
      0.029955100268125534,
      0.09985033422708511,
      0.09985033422708511,
      0.039940133690834045,
      0.029955100268125534,
      0.6190720796585083,
      0.04992516711354256,
      0.0898653045296669,
      0.0,
      0.06989523768424988,
      0.13979047536849976,
      0.0898653045296669,
      0.06989523768424988,
      0.12980544567108154,
      0.019970066845417023,
      0.029955100268125534,
      0.04992516711354256,
      0.0,
      0.039940133690834045,
      0.0,
      0.13979047536849976,
      0.04992516711354256,
      0.029955100268125534,
      0.05991020053625107,
      0.029955100268125534,
      0.009985033422708511,
      0.0,
      0.039940133690834045,
      0.0,
      0.019970066845417023,
      0.009985033422708511,
      0.039940133690834045,
      0.0,
      0.019970066845417023,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.029955100268125534,
      0.07988026738166809,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.039940133690834045,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.039940133690834045,
      0.0,
      0.0,
      0.0,
      0.029955100268125534,
      0.05991020053625107,
      0.009985033422708511,
      0.009985033422708511,
      0.05991020053625107,
      0.009985033422708511,
      0.05991020053625107,
      0.04992516711354256,
      0.04992516711354256,
      0.019970066845417023,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.039940133690834045,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.029955100268125534,
      0.0,
      0.029955100268125534,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.04992516711354256,
      0.019970066845417023,
      0.029955100268125534,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.06989523768424988,
      0.0,
      0.0,
      0.0,
      0.039940133690834045,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.039940133690834045,
      0.019970066845417023,
      0.029955100268125534,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.05991020053625107,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.029955100268125534,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.029955100268125534,
      0.039940133690834045,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.029955100268125534,
      0.0,
      0.0,
      0.0,
      0.05991020053625107,
      0.06989523768424988,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.029955100268125534,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.029955100268125534,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.0,
      0.019970066845417023,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.029955100268125534,
      0.029955100268125534,
      0.039940133690834045,
      0.019970066845417023,
      0.04992516711354256,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.029955100268125534,
      0.009985033422708511,
      0.019970066845417023,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.029955100268125534,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.009985033422708511,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.009985033422708511,
      0.039940133690834045,
      0.029955100268125534,
      0.039940133690834045,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.019970066845417023,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.0,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.0,
      0.019970066845417023,
      0.029955100268125534,
      0.029955100268125534,
      0.029955100268125534,
      0.029955100268125534,
      0.029955100268125534,
      0.009985033422708511,
      0.029955100268125534,
      0.009985033422708511,
      0.029955100268125534,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.009985033422708511,
      0.0,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.019970066845417023,
      0.009985033422708511,
      0.019970066845417023,
      0.009985033422708511,
      0.009985033422708511,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "cluster_members": [
      7
    ],
    "resonance_score": 0.0,
    "narrative_centrality": 0.0
  },
  {
    "name": "Acknowledgments References Kautz. 2017. reinforcement learning through asynchronous advantage actor-",
    "embedding": [
      0.3563859462738037,
      0.1641998589038849,
      0.1641998589038849,
      0.5707497596740723,
      -0.17996980249881744,
      0.389223575592041,
      0.20022498071193695,
      0.20022498071193695,
      0.36742907762527466,
      -0.30698904395103455,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "context": "EASE 2025, 17\u201320 June, 2025, Istanbul, T\u00fcrkiye Gaspar-Figueiredo et al.\nAcknowledgments\nThis work was funded by the GVA under the AKILA project (CIAICO/\n2021/303) and by the AEI under the UCI-Adapt project (PID2022-\n140106NB-I00). D. Gaspar-Figueiredo is funded by the GVA (ACIF/\n2021/172), which is cofunded by the EU through the ESF.\nReferences\n[1]Silvia Abrah\u00e3o, Emilio Insfr\u00e1n, Arthur Slu\u00ffters, and Jean Vanderdonckt. 2021.\nModel-based intelligent user interface adaptation: challenges and future direc-\ntions. Software and Systems Modeling 20, 5 (2021), 1335\u20131349. doi:10.1007/s10270-\n021-00909-7\n[2]John G Adair. 1984. The Hawthorne effect: a reconsideration of the methodologi-\ncal artifact. Journal of applied psychology 69, 2 (1984), 334.\n[3]Pierre A. Akiki, Arosha K. Bandara, and Yijun Yu. 2014. Adaptive Model-Driven\nUser Interface Development Systems. ACM Comput. Surv. 47, 1, Article 9 (may\n2014), 33 pages. doi:10.1145/2597999\n[4]Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, and Jan\nKautz. 2017. Reinforcement Learning through Asynchronous Advantage Actor-\nCritic on a GPU. arXiv:1611.06256 [cs.LG] https://arxiv.org/abs/1611.06256\n[5]Tita Alissa Bach, Amna Khan, Harry Hallock, Gabriela Beltr\u00e3o, and Sonia Sousa.\n2024. A systematic literature review of user trust in AI-enabled systems: An HCI\nperspective. Int. J. Hum. Comput. Interact. 40, 5 (2024), 1251\u20131266.\n[6]Sebastian Baltes and Paul Ralph. 2022. Sampling in software engineering research:\na critical review and guidelines. Empirical Software Engineering 27, 4 (28 Apr\n2022), 94. doi:10.1007/s10664-021-10072-8\n[7]Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John\nSchulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym.\narXiv:arXiv:1606.01540\n[8]Cameron B. Browne, Edward Powley, Daniel Whitehouse, Simon M. Lucas, Pe-\nter I. Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon\nSamothrakis, and Simon Colton. 2012. A Survey of Monte Carlo Tree Search\nMethods. IEEE Transactions on Computational Intelligence and AI in Games 4, 1\n(2012), 1\u201343. doi:10.1109/TCIAIG.2012.2186810\n[9]Duncan P. Brumby and Susan Zhuang. 2015. Visual Grouping in Menu Interfaces.\nInProceedings of the 33rd Annual ACM Conference on Human Factors in Com-\nputing Systems (Seoul, Republic of Korea) (CHI \u201915) . Association for Computing\nMachinery, New York, NY, USA, 4203\u20134206. doi:10.1145/2702123.2702177\n[10] Victor R Basili1 Gianluigi Caldiera and H Dieter Rombach. 1994. The goal question\nmetric approach. Encyclopedia of software engineering 1 (1994), 528\u2013532.\n[11] Ga\u00eblle Calvary, Jo\u00eblle Coutaz, David Thevenin, Quentin Limbourg, Laurent Bouil-\nlon, and Jean Vanderdonckt. 2003. A Unifying Reference Framework for multi-\ntarget user interfaces. Interacting with Computers 15, 3 (06 2003), 289\u2013308.\n[12] Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and\nDario Amodei. 2023. Deep reinforcement learning from human preferences.\narXiv:1706.03741 [stat.ML] https://arxiv.org/abs/1706.03741\n[13] Kevin Doherty and Gavin Doherty. 2018. Engagement in HCI: conception, theory\nand measurement. ACM Computing Surveys (CSUR) 51, 5 (2018), 1\u201339.\n[14] Amr Elmasry, Mostafa Kahla, Fady Ahdy, and Mahmoud Hashem. 2019. Red\u2013\nblack trees with constant update time. Acta Informatica 56, 5 (01 Jul 2019),\n391\u2013404. doi:10.1007/s00236-019-00335-9\n[15] Daniel Gaspar-Figueiredo, Marta Fern\u00e1ndez-Diego, Silvia Abrah\u00e3o, and Emilio\nInsfr\u00e1n. 2025. A Comparative Study on Reward Models for UI Adaptation with Re-\ninforcement Learning. Accepted in Empirical Software Engineering Journal(EMSE)\n(2025). Available at: https://figshare.com/s/da9556a26a047fb44e4b.\n[16] Daniel Gaspar-Figueiredo, Marta Fern\u00e1ndez-Diego, Ruben Nuredini, Silvia Abra-\nhao, and Emilio Insfran. 2024. Reinforcement Learning-Based Framework for the\nIntelligent Adaptation of User Interfaces. In Symposium on Engineering Interactive\nComputing Systems (EICS \u201924) . 40\u201348. doi:10.1145/3660515.3661329\n[17] Alexander Havrilla, Maksym Zhuravinskyi, Duy Phung, Aman Tiwari, Jonathan\nTow, Stella Biderman, Quentin Anthony, and Louis Castricato. 2023. trlX: A\nFramework for Large Scale Reinforcement Learning from Human Feedback. In\nConference on Empirical Methods in Natural Language Processing , Houda Bouamor,\nJuan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics,\nSingapore, 8578\u20138595. doi:10.18653/v1/2023.emnlp-main.530\n[18] Wiard Jorritsma, Fokie Cnossen, and Peter MA van Ooijen. 2015. Adaptive\nsupport for user interface customization: a study in radiology. International\nJournal of Human-Computer Studies 77 (2015), 1\u20139.\n[19] Maxwell K.D. 2002. Applied Statistics for Software Managers. Applied Statistics\nfor Software Managers (2002), . https://cir.nii.ac.jp/crid/1573668924056253312\n[20] Terry K. Koo and Mae Y. Li. 2016. A Guideline of Selecting and Reporting\nIntraclass Correlation Coefficients for Reliability Research. Journal of Chiropractic\nMedicine 15, 2 (2016), 155\u2013163. doi:10.1016/j.jcm.2016.02.012\n[21] Alexandra Kuznetsova, Per B. Brockhoff, and Rune H. B. Christensen. 2017.\nlmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical\nSoftware 82, 13 (2017), 1\u201326. doi:10.18637/jss.v082.i13[22] Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan\nRossi, and Thien Nguyen. 2023. Okapi: Instruction-tuned Large Language Models\nin Multiple Languages with Reinforcement Learning from Human Feedback. In\nConference on Empirical Methods in Natural Language Processing , Yansong Feng\nand Els Lefever (Eds.). Association for Computational Linguistics, Singapore,\n318\u2013327. doi:10.18653/v1/2023.emnlp-demo.28\n[23] Thomas Langerak, Sammy Christen, Mert Albaba, Christoph Gebhardt, and\nOtmar Hilliges. 2022. MARLUI: Multi-Agent Reinforcement Learning for Goal-\nAgnostic Adaptive UIs. arXiv preprint arXiv:2209.12660 , (2022), .\n[24] Thomas Langerak, Sammy Christen, Mert Albaba, Christoph Gebhardt, Christian\nHolz, and Otmar Hilliges. 2024. MARLUI: Multi-Agent Reinforcement Learning\nfor Adaptive Point-and-Click UIs. Proc. ACM Hum.-Comput. Interact. 8, EICS,\nArticle 253 (June 2024), 27 pages. doi:10.1145/3661147\n[25] Janette Lehmann, Mounia Lalmas, Elad Yom-Tov, and Georges Dupret. 2012.\nModels of User Engagement. In User Modeling, Adaptation, and Personalization ,\nJudith Masthoff, Bamshad Mobasher, Michel C. Desmarais, and Roger Nkambou\n(Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 164\u2013175.\n[26] Kent L Norman, Ben Shneiderman, B Harper, and L Slaughter. 1998. Question-\nnaire for user interaction satisfaction. Available at: https://site.unibo.it/hfrs/en/\nquestionnaire-and-scales-2/quis.\n[27] Heather L O\u2019Brien and Elaine G Toms. 2008. What is user engagement? A\nconceptual framework for defining user engagement with technology. Journal of\nthe American society for Information Science and Technology 59, 6 (2008), 938\u2013955.\n[28] Heather L. O\u2019Brien, Paul Cairns, and Mark Hall. 2018. A practical approach to\nmeasuring user engagement with the refined user engagement scale (UES) and\nnew UES short form. International Journal of Human-Computer Studies 112 (2018),\n28\u201339. doi:10.1016/j.ijhcs.2018.01.004\n[29] Ga\u00eblle Calvary Sara Bouzit and Denis Ch\u00eane et al. 2016. A Comparison of\nShortcut and Step-by-Step Adaptive Menus for Smartphones. European Workshop\non Imagery and Cognition (2016), 1\u201312. doi:10.14236/ewic/HCI2016.26\n[30] R Core Team. 2013. R: A language and environment for statistical computing. R\nFoundation for Statistical Computing. (No Title) (2013), .\n[31] Ergonomics of human-system interaction Technical Committee ISO/TC 159.\nSubcommittee SC 4. 2018. ISO 9241-11:2018 Ergonomics of Human-system\nInteraction: Egonomie de L\u2019interaction Homme-syst\u00e8me. Usability : definitions\nand concepts. Utilisabilit\u00e9 : d\u00e9finitions et concepts. Part 11. Partie 11 . ISO, .\nhttps://books.google.es/books?id=Uc8dygEACAAJ\n[32] Kashyap Todi, Gilles Bailly, Luis Leiva, and Antti Oulasvirta. 2021. Adapting\nUser Interfaces with Model-Based Reinforcement Learning. In Proceedings of the\n2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan)\n(CHI \u201921) . Association for Computing Machinery, New York, NY, USA, Article\n573, 13 pages. doi:10.1145/3411764.3445497\n[33] Sira Vegas, Cecilia Apa, and Natalia Juristo. 2015. Cross-Over Designs in Software\nEngineering Experiments: Benefits and Perils. IEEE Transactions on Software\nEngineering 42 (01 2015), 1\u20131. doi:10.1109/TSE.2015.2467378\n[34] Gianni Viano, Andrea Parodi, James Alty, Chris Khalil, Inaki Angulo, Daniele\nBiglino, Michel Crampes, Christophe Vaudry, Veronique Daurensan, and Philippe\nLachaud. 2000. Adaptive User Interface for Process Control Based on Multi-\nAgent Approach. In Proc. of the Working Conference on Advanced Visual Interfaces\n(Palermo, Italy) (AVI \u201900) . Association for Computing Machinery, New York, NY,\nUSA, 201\u2013204. doi:10.1145/345513.345316\n[35] Dmitry Vidmanov and Alexander Alfimtsev. 2024. Mobile User Interface Adapta-\ntion Based on Usability Reward Model and Multi-Agent Reinforcement Learning.\nMultimodal Technologies and Interaction 8, 4 (2024), . doi:10.3390/mti8040026\n[36] Wei Wang, Hourieh Khalajzadeh, John Grundy, Anuradha Madugalla, and\nHumphrey O. Obie. 2024. Adaptive User Interfaces for Software Supporting\nChronic Disease. In International Conference on Software Engineering (Lisbon,\nPortugal) (ICSE-SEIS\u201924) . Association for Computing Machinery, New York, NY,\nUSA, 118\u2013129. doi:10.1145/3639475.3640104\n[37] Claes Wohlin, Per Runeson, Martin H\u00f6st, Magnus C. Ohlsson, Bj\u00f6rn Regnell, and\nAnders Wessl\u00e9n. 2012. Empirical Strategies . Springer Berlin Heidelberg, Berlin,\nHeidelberg, 9\u201336. doi:10.1007/978-3-642-29044-2_2\n[38] Yifu Yuan, Jianye Hao, Yi Ma, Zibin Dong, Hebin Liang, Jinyi Liu, Zhixin Feng,\nKai Zhao, and Yan Zheng. 2024. Uni-RLHF: Universal Platform and Benchmark\nSuite for Reinforcement Learning with Diverse Human Feedback. arXiv preprint\narXiv:2402.02423 (2024), .\n[39] Lamia Zouhaier, Yousra BenDalyHlaoui, and Leila Ben Ayed. 2023. Adaptive user\ninterface based on accessibility context. Multimedia Tools and Applications 82, 23\n(01 Sep 2023), 35621\u201335650. doi:10.1007/s11042-023-14390-5",
    "passage_embedding": [
      0.17028987407684326,
      0.6279439330101013,
      0.19157610833644867,
      0.2660779356956482,
      0.03192935138940811,
      0.08514493703842163,
      0.08514493703842163,
      0.042572468519210815,
      0.10643117129802704,
      0.0,
      0.14900363981723785,
      0.010643117129802704,
      0.06385870277881622,
      0.042572468519210815,
      0.0,
      0.06385870277881622,
      0.03192935138940811,
      0.06385870277881622,
      0.042572468519210815,
      0.06385870277881622,
      0.0,
      0.042572468519210815,
      0.021286234259605408,
      0.11707428842782974,
      0.010643117129802704,
      0.010643117129802704,
      0.03192935138940811,
      0.0,
      0.042572468519210815,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.06385870277881622,
      0.0,
      0.0,
      0.0,
      0.05321558564901352,
      0.021286234259605408,
      0.23414857685565948,
      0.0,
      0.12771740555763245,
      0.06385870277881622,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.03192935138940811,
      0.06385870277881622,
      0.0,
      0.042572468519210815,
      0.06385870277881622,
      0.22350546717643738,
      0.03192935138940811,
      0.0,
      0.0,
      0.0,
      0.10643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03192935138940811,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.021286234259605408,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.05321558564901352,
      0.03192935138940811,
      0.0,
      0.0,
      0.0,
      0.042572468519210815,
      0.042572468519210815,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.09578805416822433,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.08514493703842163,
      0.0,
      0.021286234259605408,
      0.0,
      0.010643117129802704,
      0.021286234259605408,
      0.042572468519210815,
      0.021286234259605408,
      0.0,
      0.06385870277881622,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.10643117129802704,
      0.10643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.05321558564901352,
      0.010643117129802704,
      0.0,
      0.0,
      0.03192935138940811,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.05321558564901352,
      0.021286234259605408,
      0.03192935138940811,
      0.0,
      0.042572468519210815,
      0.021286234259605408,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.03192935138940811,
      0.05321558564901352,
      0.0,
      0.05321558564901352,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.07450181990861893,
      0.07450181990861893,
      0.07450181990861893,
      0.07450181990861893,
      0.07450181990861893,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.042572468519210815,
      0.042572468519210815,
      0.03192935138940811,
      0.042572468519210815,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.06385870277881622,
      0.06385870277881622,
      0.06385870277881622,
      0.06385870277881622,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.03192935138940811,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.042572468519210815,
      0.042572468519210815,
      0.010643117129802704,
      0.05321558564901352,
      0.05321558564901352,
      0.05321558564901352,
      0.03192935138940811,
      0.0,
      0.0,
      0.03192935138940811,
      0.03192935138940811,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.010643117129802704,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03192935138940811,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.03192935138940811,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.042572468519210815,
      0.042572468519210815,
      0.042572468519210815,
      0.042572468519210815,
      0.042572468519210815,
      0.042572468519210815,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.021286234259605408,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.021286234259605408,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.03192935138940811,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.010643117129802704,
      0.0,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.010643117129802704,
      0.0,
      0.0,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.021286234259605408,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "cluster_members": [
      9
    ],
    "resonance_score": 0.0,
    "narrative_centrality": 0.0
  }
]